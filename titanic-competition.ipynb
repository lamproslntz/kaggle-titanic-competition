{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\n\n# vectorization\nfrom sklearn.preprocessing import LabelEncoder\n\n# misc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\n\n# models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load train and test data\n\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Structure of the Data\n\nSize of **training examples**: (891,12) <br/>\nSize of **test data**: (418,11)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train dataset size: {train.shape}')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Test dataset size: {test.shape}')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values(df, columns):\n    \"\"\" Finds number of rows where specified columns are missing values.\n    \n    Args:\n        df:\n            The dataframe to be analyzed.\n        columns:\n            The list of columns of the dataframe.\n    \n    Returns:\n         A dictionary with the columns and the number of values they are missing.\n    \"\"\"\n    missing = {}\n    \n    for column in columns:\n        total = df[column].value_counts().sum()\n        missing[column] = df.shape[0] - total\n    \n    return missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = missing_values(train, train.columns)\nprint(f'Total values that each column should have: {train.shape[0]}')\nprint(f'Total values that each column is missing:')\nmissing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Preprocess"},{"metadata":{},"cell_type":"markdown","source":"### 3.1 PassengerId\n\nThe **PassengerId** column has unique values for each row in the trainning examples. Thus, it won't help in classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['PassengerId'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Name\n\nThe **Name** column has unique values for each row in the trainning examples. Thus, it won't help in classification. <br/>\nHowever, we can create an new feature from it, called **Title** which will be the title of each person."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain = train.drop(['Name'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest = test.drop(['Name'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Age\n\nThe **Age** column is missing a lot of values. My intuition is that the age of a person played an important role in his survival and so we'll fill them using the mean of the ages with respect to the persons title. Also, we'll create ranges of the age so it is discretised."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'] = train['Age'].fillna(train.groupby('Title')['Age'].transform('median'))\ntrain['Age'] = pd.cut(train['Age'], bins=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Age'] = test['Age'].fillna(test.groupby('Title')['Age'].transform('median'))\ntest['Age'] = pd.cut(test['Age'], bins=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 Ticket"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Ticket column has {len(train.Ticket.unique())} different values.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **Ticket** column has a lot of different values. Specifically, 681/891 different values. So, we'll drop this column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(['Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.5 Fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Fare column has {len(train.Fare.unique())} different values.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The **Fare** column has a some unique values (248/891). We'll not drop this column, but we'll create ranges, so it becomes categorical."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Fare'] = pd.cut(train['Fare'], bins=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Fare'] = pd.cut(test['Fare'], bins=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6 Embarked\n\nThe **Embarked** column has 2 missing values. We'll not remove these rows but we'll fill them with the most frequent value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the most frequent value in 'Embarked' column\nval = train['Embarked'].value_counts().idxmax()\n\n# replace null values\ntrain['Embarked'] = train['Embarked'].fillna(value=val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = test['Embarked'].value_counts().idxmax()\ntest['Embarked'] = test['Embarked'].fillna(value=val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.7 Cabin\n\nThe **Cabin** column has a lot of missing values. We'll only keep the first letter of the cabin and create a new cabin class, namely 'N' for these rows that have missing values in this column.\n\n\n**Note:** Some people had two cabins! "},{"metadata":{"trusted":true},"cell_type":"code","source":"# keep the first letter from the cabin\ntrain['Cabin'] = train['Cabin'].str[:1]\n\n# fill missing data in \"Cabin\" column using 'N' (we'll assume that n is a cabin class)\ntrain['Cabin'] = train['Cabin'].fillna(value='N')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Cabin'] = test['Cabin'].str[:1]\ntest['Cabin'] = test['Cabin'].fillna(value='N')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.8 Alone\n\nThe **SibSp** column shows the number of siblings/spouses of a person aboard the Titanic. Similarly, **Parch** shows the number of parents/children of a person aboard the Titanic.\n\nMy intuition is that if a person wasn't alone on the Titanic he could have help from his family, or alternatively he could have sacrificed himself/herself to help them (lower chances of survival). So, we'll can combine them in a single feature called **Alone**, which takes 0/1 values, and drop **SibSp** and **Parch**."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Alone'] = 1\ntrain.loc[(train['SibSp'] >= 1) | (train['Parch'] >= 1), 'Alone'] = 0\n\n# drop SibSp and Parch\ntrain = train.drop(['SibSp', 'Parch'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Alone'] = 1\ntest.loc[(test['SibSp'] >= 1) | (test['Parch'] >= 1), 'Alone'] = 0\ntest = test.drop(['SibSp', 'Parch'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training examples after preprocessing:')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test data after preprocessing:')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Vectorize\n\nWe'll try categorical encoding vectors."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_enc_cat = train.apply(LabelEncoder().fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Categorical encoding vector size: {train_enc_cat.shape}')\ntrain_enc_cat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Fitting Models and Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_enc_cat.Survived\nX_train = train_enc_cat.drop(['Survived'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train data size: {X_train.shape}')\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train labels size: {y_train.shape}')\ny_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\n\n# cross validation\nscores = cross_val_score(lr, X_train, y_train, cv=10)\n\n# accuracy\nprint(f'Accuracy of Logistic Regression: {scores.mean()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.2 Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\n\n# cross validation\nscores = cross_val_score(dt, X_train, y_train, cv=10)\n\n# accuracy\nprint(f'Accuracy for Decision Tree: {scores.mean()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3 Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 100 decision tree classifiers\n# feture selection with gini\n# decision trees have max depth\nrf = RandomForestClassifier()\n\n# cross validation\nscores = cross_val_score(rf, X_train, y_train, cv=10)\n\n# accuracy\nprint(f'Accuracy for Random Forest: {scores.mean()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.4 Support Vector Machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"# values will be scaled using equation (val-mean)/std\nsvc = make_pipeline(StandardScaler(), LinearSVC())\n\n# cross validation\nscores = cross_val_score(svc, X_train, y_train, cv=10)\n\n# accuracy\nprint(f'Accuracy for Linear SVC: {scores.mean()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Predict on Test"},{"metadata":{},"cell_type":"markdown","source":"### 6.1 Vectorize"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test data should have the same format (columns) as training examples\ncolumns = X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_enc_cat = test[columns].apply(LabelEncoder().fit_transform)\n\nX_test = test_enc_cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.2 Predict with best model\n\nBest model up to now is logistic regression classifier, with training accuracy 77%."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = lr\n\n# train model\nbest_model.fit(X_train, y_train)\n\n# predict on test data\ny_pred = best_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8 Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test['PassengerId']\nsubmission['Survived'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Submission size: {submission.shape}')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('/kaggle/working/logistic-regression.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}